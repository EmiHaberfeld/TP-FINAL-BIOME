---
title: "Trabajo Práctico Final  \nBiometría II - 2021"
author: "Matías Alemán, Milagros Azcueta, Manuel Fiz, Emilia Haberfeld, Diego Kafer, Ilan Shalom"
date: "21/10/2021"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción
Los animales se encuentran constantemente tomando decisiones respecto a cuándo alimentarse, aparearse, dormir, y demás acciones (1). A través de aprendizajes y experiencias previas, son capaces de comparar dos o más escenarios probables antes de realizar cualquier acción (2). La generación de una expectativa respecto a dichos escenarios es un proceso que permite a los animales predecir la aparición de estímulos (tanto aversivos como apetitivos) y de este modo, adaptar su comportamiento (3). Esta expectativa incide directamente en sus capacidades mnésicas, debido a que el aprendizaje depende de asociaciones entre claves externas y representaciones internas de dichas claves (4). Este proceso ha sido ampliamente estudiado en vertebrados, pero hay menos información disponible en invertebrados.

El objetivo de este trabajo es estudiar la modulacion de memorias a largo termino a partir de cambios en la expectativa de la recompensa. El modelo experimental es la abeja Apis mellifera y los experimentos fueron realizados en un contexto controlado dentro del laboratorio.

# Materiales y métodos
Abejas Apis mellifera fueron entrenadas bajo un condicionamiento clásico del reflejo de extensión de probóscide (PER, por sus siglas en inglés) (5,6): se administra un odorante a la vez que se tocan las antenas con una gota de sacarosa. La abeja extiende su probóscide como reflejo de este estímulo, y en ese momento se la alimenta con una solución azucarada. De este entrenamiento, recibieron 4 ensayos. Terminada la etapa de entrenamiento, se realizaron tres testeos donde se presentó solo el odorante a 3, 24 y 48 hs posteriores al último ensayo de entrenamiento.

Las abejas se dividieron en 4 grupos experimentales dependiendo de la sacarosa recibida en las antenas y en la probóscide. Los grupos "constante alto" y "constante bajo" recibieron tanto en las antenas como en la probóscide azúcar de concentración 1,5 M y 0,5 M respectivamente. Por otro lado, los grupos "contraste positivo" y "contraste negativo" recibieron azúcar de distinta concentración en cada pieza sensorial: los animales del grupo contraste positivo recibieron sacarosa 0,5 M en las antenas y 1,5 M en su probóscide. Por otro lado, los animales del contraste negativo recibieron azúcar 1,5 M en las antenas para luego ser alimentadas con sacarosa 0,5 M.

Como VR se midió la extensión de la probóscide frente al olor (sí-no). Al ser una variable dicotómica, la distribución de probabilidades esperada es una Bernoulli. El diseño es de medidas repetidas ya que cada abeja fue medida 7 veces (4 ensayos de entrenamiento + 3 testeos). Se realizó estadística descriptiva de la etapa de entrenamiento y un modelo estadístico para la etapa de evaluación ya que el mayor interés del análisis está depositado en las diferencias observables durante esta etapa. Como variables explicatorias se incluyeron:

VE1: Tiempo de testeo → cualitativa fija de 3 niveles (3, 24, 48 hs).
VE2: Tratamiento → cualitativa fija de 4 niveles (constante alto, constante bajo, contraste positivo, contraste negativo)
VE3: ID de abeja → cualitativa aleatoria de 132 niveles (abeja 1 a 132).
VE4: Semana de trabajo → cualitativa aleatoria de 7 niveles (semanas 1 a 7). Covariable.

Se implementó un modelo lineal generalizado condicional con la función glmmTMB de la librería glmmTMB. Se optó por un modelo condicional ya que se compararon modelos marginales con distintas matrices de correlación y, a partir de un ranking de QIC (el cual compara modelos según su verosimilitud y cantidad de parámetros estimados), el más conveniente resultó un modelo marginal con matriz de simetría compuesta. Como los modelos condicionales tienen implícita una matriz de simetría compuesta y resultan más familiares para su implementación en R, se eligió esta opción. 

Contrastes a priori:
Se espera que el grupo contraste positivo aprenda la asociación olor-azúcar más fuertemente que el constante alto, debido a un mayor estado motivacional gracias a la "sorpresa" recibida en la probóscide (azúcar 1,5 M) en contraste con el azúcar esperada que tocó las antenas segundos antes (0,5 M). Caso opuesto, se espera que la proporción de animales de contraste negativo que aprendan la asociación sea menor que la proporción de constante bajo, debido a un estado motivacional degradado por la "decepción" de recibir azúcar 0,5 M cuando esperaban 1,5 M.

# Resultados
Presentar gráficos y/o Tablas. Editar lo que sea necesario de formato para que el lector comprenda. Informar medias, magnitud del efecto, letras de significación cuando corresponda. Supuestos: salvo excepciones, sólo mencionarlos y mencionar su cumplimiento. Incluir decisiones metodológicas.

En el primer tiempo de evaluación (3 hs) no se observaron diferencias significativas en los contrastes (p>0,05). 
A 24 hs se observaron diferencias significativas entre los grupos CONSTANTE ALTO y CONTRASTE POSITIVO. Se estima que la chance de extensión de probóscide para el grupo CONTRASTE POSITIVO aumenta entre un 2,96% y un 84,2% respecto al grupo CONSTANTE ALTO, con un 95% de confianza (p<0,05). No se observaron diferencias significativas en la comparación CONSTANTE BAJO vs CONTRASTE NEGATIVO a 24 hs (p>0,05). 
En la evaluación a 48 hs, se observaron diferencias significativas entre los grupos CONSTANTE BAJO y CONTRASTE NEGATIVO. Se estima que la chance de extensión de probóscide para el grupo CONTRASTE NEGATIVO disminuye entre un 27,26% y un 4.720,20% respecto al grupo CONSTANTE BAJO, con un 95% de confianza (p<0,05). No se observaron diferencias significativas en la comparación CONSTANTE ALTO vs CONTRASTE POSITIVO a 48 hs (p>0,05), aunque la tendencia de las estimaciones coincide con lo observado a 24 hs.

# Discusión o conclusión
Debido a que la interacción tratamiento*tiempo resultó significativa, se realizaron contrastes ortogonales teniendo en cuenta ambas variables. Si nos situamos en primer lugar en las comparaciones en t = 3 hs, se observa que ninguno de los dos contrastes propuestos mostró diferencias significativas. Lo que es más curioso aún es que la tendencia de la respuesta parece ser opuesta a la esperada por los contrastes a priori: los grupos contraste negativo y constante bajo son aquellos que mayor proporción de PER presentaron. Debido a que la memoria observada a las 3 hs posteriores de finalizado el último ensayo de entrenamiento es una memoria de corto término, puede estar influida por diversos fenómenos ajenos al tratamiento aplicado. En particular, se propone que en este punto temporal hay un conflicto en relación a la expresión de la memoria generada. Los animales de los grupos contraste negativo y constante bajo son los que menos azúcar ingirieron (en términos nutricionales), ya que siempre consumieron azúcar de concentración 0,5 M. Por lo tanto, es muy probable que a 3 hs estos animales estén más motivados que los otros dos grupos y que por ende, lo que parece ser una mayor retención de la memoria (que sólo es posible de observar a través de la extensión de la probóscide, en este experimento) sea un reflejo de la motivación de estos animales por seguir ingiriendo azúcar. En contraste, las abejas de los grupos contraste positivo y constante alto habrían alcanzado un nivel de saciedad más alto, respondiendo menos al estímulo (odorante). [agregar algunas citas a esto, después busco]

[discusión 24 hs]

[discusión 48 hs, acá para pos-alto podemos sumar lo de la varianza de las bernoulli y que por eso sería difícil ver diferencias]

# Bibliografía
1. McFarland, D. J. Decision making in animals. Nature 269, 15–21 (1977).
2. Menzel, R. & Giurfa, M. Dimensions of Cognition in an Insect, the Honeybee. Behav. Cogn. Neurosci. Rev. 5, 24–40 (2006).
3. Gil, M., De Marco, R. J. & Menzel, R. Learning reward expectations in honeybees. Learn. Mem. 14, 491–6 (2007).
4. Rescorla, R. A. A Pavlovian analysis of goal-directed behavior. Am. Psychol. 42, 119–129 (1987).
5. Bitterman, M. E., Menzel, R., Fietz, A. & Schäfer, S. Classical conditioning of proboscis extension in honeybees (Apis mellifera). J. Comp. Psychol. 97, 107–119 (1983).
6. Takeda, K. Classical conditioned response in the honey bee. J. Insect Physiol. 6, 168–179 (1961).

```{r}
#################################### SCRIPT ####################################

# Borrar objetos de la memoria
rm(list = ls()) 

################################################################################
####################### CARGA DE LIBRERIAS Y DATOS: ############################
################################################################################

library(readxl)    # datos de excel
library(reshape2)  # melt
library(pastecs)   # tapply
library(ggplot2)   # gráficos
library(ggeffects) # ggpredict (todavía no lo usamos)
library(dplyr)
library(geepack)   # modelado con geeglm
library(MuMIn)     # model.sel
library(glmmTMB)   # modelado con glmmTMB
library(car)       # Anova
library(emmeans)   # comparaciones


setwd("D:/Milagros Azcueta/Documents/GitHub/TP-FINAL-BIOME")
datos <- read_excel("datos.xlsx")
str(datos)
datos$SEMANA         <- as.factor(datos$SEMANA)
datos$ID             <- as.factor(datos$ID)
datos$ANT            <- as.factor(datos$ANT)
datos$PROB           <- as.factor(datos$PROB)
datos$TRATAMIENTO    <- as.factor(datos$TRATAMIENTO)
str(datos)
# Colmena no la vamos a incluir en el analisis porque esta explicada por Semana.

################################################################################
############################### DESCRIPTIVA ####################################
################################################################################

################## ENTRENAMIENTO:

# PASAMOS DATOS ENTRENAMIENTO A LONG:
wide_entr <- datos[,c(1,2,3,4,5,6,7,8,9)]
long_entr <- melt(wide_entr,
                id.vars = c("SEMANA", "ID", "ANT", "PROB", "TRATAMIENTO"),
                variable.name = "tiempo_entr",
                value.name = "rta")

# PROBABILIDAD DE EXITO SEGUN TRATAMIENTO Y TIEMPO:
prob_exito_entr <- round(tapply(long_entr$rta,list(long_entr$TRATAMIENTO,long_entr$tiempo_entr),mean),2)
prob_exito_entr
# Creamos un data frame en formato long con estos valores:
prob_exito_entr_long <- as.data.frame.table(prob_exito_entr)
colnames(prob_exito_entr_long) <- c("TRATAMIENTO","nro_ensayo","proporcion_exitos")

# Graficamente:
gp_entr <- ggplot(prob_exito_entr_long, aes(x=nro_ensayo, y=proporcion_exitos, 
                                        colour=TRATAMIENTO, group=TRATAMIENTO)) +
  geom_line(aes(linetype=TRATAMIENTO), size=.6) +
  geom_point(aes(shape=TRATAMIENTO),size=3) +
  labs(x="Número de ensayo",y="Proporción de éxitos",title="Curva de aprendizaje") +
  ylim(0,1) + theme_bw()
gp_entr


################## TESTEO:

# PASAMOS DATOS TEST A LONG:
wide_testeo <- datos[,c(1,2,3,4,5,10,11,12)]
long_testeo <- melt(wide_testeo,
                  id.vars = c("SEMANA", "ID", "ANT", "PROB", "TRATAMIENTO"),
                  variable.name = "tiempo_testeo",
                  value.name = "rta")

# PROBABILIDAD DE EXITO SEGUN TRATAMIENTO Y TIEMPO EN TESTEO:
prob_exito_testeo <- round(tapply(long_testeo$rta,list(long_testeo$TRATAMIENTO,long_testeo$tiempo_testeo), mean),2)
prob_exito_testeo
# Creamos un data frame en formato long con estos valores:
prob_exito_testeo_long <- as.data.frame.table(prob_exito_testeo)
colnames(prob_exito_testeo_long) <- c("TRATAMIENTO","tiempo_testeo","proporcion_exitos")
# Graficamente:
gp_testeo <- ggplot(prob_exito_testeo_long, aes(x=tiempo_testeo, y=proporcion_exitos,
                                              colour=TRATAMIENTO, group=TRATAMIENTO)) + 
  geom_line(aes(linetype=TRATAMIENTO), size=.6) +
  geom_point(aes(shape=TRATAMIENTO),size=3) +
  labs(x="Tiempo de testeo",y="Proporcion de exitos",
       title="Proporcion de éxitos en función del tiempo y el tratamiento") +
  ylim(0,1) + theme_bw()
gp_testeo


################## SEMANA COMO COVARIABLE:

prob_exito_semana <- round(tapply(long_testeo$rta,list(long_testeo$SEMANA,long_testeo$tiempo_testeo), mean),2)
prob_exito_semana
# Creamos un data frame en formato long con estos valores:
prob_exito_semana_long <- as.data.frame.table(prob_exito_semana)
colnames(prob_exito_semana_long) <- c("SEMANA","tiempo_testeo","proporcion_exitos")

# Graficamente:
gp_semana <- ggplot(prob_exito_semana_long, aes(x=tiempo_testeo, y=proporcion_exitos, colour=SEMANA,group=SEMANA)) +
  geom_line(aes(linetype=SEMANA), size=.6) +
  geom_point(aes(shape=SEMANA),size=3) +
  labs(x="Tiempo de testeo",y="Proporción de éxitos",title="Proporcion de éxitos en función del tiempo y la semana") +
  ylim(0,1) + theme_bw()
gp_semana

################################################################################
############################### MODELADO #######################################
################################################################################

################## PRIMERA PROPUESTA: MODELO MARGINAL (GEEGLM)

# Para geeglm, las filas del data frame tienen que estar ordenadas por paciente y por tiempo:
long_testeo <- arrange(long_testeo,ID)

# Notacion de matrices de covarianza en geeglm:
# Estructura simple: independence
# Simetria compuesta: exchangeable
# AR1: ar1
# Desestructurada: unstructured

### A) triple interaccion
m1 <- geeglm(formula=rta~ANT*PROB*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="independence")
anova(m1)
m2 <- geeglm(formula=rta~ANT*PROB*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="exchangeable")
anova(m2)
m3 <- geeglm(formula=rta~ANT*PROB*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="ar1")
anova(m3)
m4 <- geeglm(formula=rta~ANT*PROB*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="unstructured")
anova(m4)

### B) tratamiento*tiempo
m5 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="independence")
anova(m5)
m6 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="exchangeable")
anova(m6)
m7 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="ar1")
anova(m7)
m8 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="unstructured")
anova(m8)

## SELECCION DE MODELOS (en geeglm rankeamos por QIC):
model.sel(m1,m2,m3,m4,m5,m6,m7,m8, rank = QIC)

# Estructura simple: la sacamos porque no estariamos declarando dependencia de datos entre tiempos para una misma abeja.
# Simetria compuesta: decimos que para cada abeja hay una misma correlacion entre tiempos.
# AR1: la sacamos porque a pesar de tener la misma cantidad de parámetros que la de simetria compuesta, tiene un peor ajuste porque nuestros tiempos no son equidistantes como asume AR1, entonces el QIC es mayor.
# Desestructurada: la sacamos porque estima mas parametros, por eso el QIC da un poco mas alto.


################## SEGUNDA PROPUESTA: MODELO CONDICIONAL (GLMMTMB)

# Como elegimos simetria compuesta, probamos un modelo condicional:

# glmmTMB es bueno para mixtos y muchos niveles del aleatorio.
m9 <- glmmTMB(rta ~ TRATAMIENTO*tiempo_testeo + SEMANA + (1|ID), data=long_testeo, family="binomial")
m10 <- glmmTMB(rta ~ TRATAMIENTO*tiempo_testeo +  (1|SEMANA) + (1|ID), data=long_testeo, family="binomial")
# No cambia info biológica y obtenemos más información porque podemos generalizar las semanas (al menos a todas las semanas que Mili podría haber ido con buen clima).

################################################################################
########################### EVALUACIÓN DE SUPUESTOS ############################
################################################################################

## Parte fija:
library(DHARMa)
sim <- simulateResiduals(m9, n=1000)
plot(sim)

## Parte aleatoria:
Bi<-unlist(ranef(m9))
# QQPlot con estos residuos:
qqPlot(Bi,main="QQ Plot efectos aleatorios abeja (ID)")
# Prueba de shapiro:
shapiro.test(Bi)

# NO HAY EVIDENCIAS PARA RECHAZAR SUPUESTOS DE LA PARTE FIJA NI ALEATORIA.

################################################################################
########################## ESTIMACIÓN E INFERENCIA #############################
################################################################################

Anova(m9) # Semana e interaccion significativas
Anova(m10)
summary(m9)
summary(m10)

################################################################################
############################### COMPARACIONES ##################################
################################################################################

# Seteamos el emmeans:
options(emmeans= list(emmeans = list(infer = c(TRUE, TRUE)),
                      contrast = list(infer = c(TRUE, TRUE))))

##### PRIMERA PROPUESTA: BONFERRONI (TENEMOS COMPARACIONES A PRIORI Y BONFERRONI SE PUEDE PONER EN EL EMMEANS)

bonferroni<-emmeans(m9,~TRATAMIENTO*tiempo_testeo,type="response",
                contr=list("3hs_alto_pos"=c(1,0,0,-1,0,0,0,0,0,0,0,0), 
                     "3hs_bajo_neg"=c(0,1,-1,0,0,0,0,0,0,0,0,0), 
                     "24hs_alto_pos"=c(0,0,0,0,1,0,0,-1,0,0,0,0), 
                     "24hs_bajo_neg"=c(0,0,0,0,0,1,-1,0,0,0,0,0), 
                     "48hs_alto_pos"=c(0,0,0,0,0,0,0,0,1,0,0,-1), 
                     "48hs_bajo_neg"=c(0,0,0,0,0,0,0,0,0,1,-1,0)),
                adjust="bonferroni")

bonferroni # Nos da la probabilidad para cada grupo y las comparaciones (en odds ratio) porque lo seteamos en options más arriba en el código.
# No da nada significativo pero puede ser porque son muchas comparaciones para Bonferroni (multiplica los p-valores por 6 en este caso).
# Hicimos las comparaciones a mano y las cuentas están bien.

# Podemos graficar los IC y las flechas rojas para comparar.
plot(bonferroni, comparisons=T)
# No sabemos si está comparando bien porque el gráfico no está dividido en las 6 comparaciones.


##### SEGUNDA PROPUESTA: CONTRASTES ORTOGONALES (TENEMOS COMPARACIONES A PRIORI Y SEGÚN JOSÉ SI NO ACLARAMOS adjust="bonferroni" EMMEANS HACE ORTOGONALES. CHECKEADO.)

ortogonales<-emmeans(m9,~TRATAMIENTO*tiempo_testeo,type="response",
                contr=list("3hs_alto_pos"=c(1,0,0,-1,0,0,0,0,0,0,0,0), 
                     "3hs_bajo_neg"=c(0,1,-1,0,0,0,0,0,0,0,0,0), 
                     "24hs_alto_pos"=c(0,0,0,0,1,0,0,-1,0,0,0,0), 
                     "24hs_bajo_neg"=c(0,0,0,0,0,1,-1,0,0,0,0,0), 
                     "48hs_alto_pos"=c(0,0,0,0,0,0,0,0,1,0,0,-1), 
                     "48hs_bajo_neg"=c(0,0,0,0,0,0,0,0,0,1,-1,0)))
ortogonales_10<-emmeans(m10,~TRATAMIENTO*tiempo_testeo,type="response",
                contr=list("3hs_alto_pos"=c(1,0,0,-1,0,0,0,0,0,0,0,0), 
                     "3hs_bajo_neg"=c(0,1,-1,0,0,0,0,0,0,0,0,0), 
                     "24hs_alto_pos"=c(0,0,0,0,1,0,0,-1,0,0,0,0), 
                     "24hs_bajo_neg"=c(0,0,0,0,0,1,-1,0,0,0,0,0), 
                     "48hs_alto_pos"=c(0,0,0,0,0,0,0,0,1,0,0,-1), 
                     "48hs_bajo_neg"=c(0,0,0,0,0,0,0,0,0,1,-1,0)))

ortogonales # Dan significativas las comparaciones constante alto vs contraste positivo a las 24 hs y constante bajo vs contraste negativo a las 48 hs. El director de Mili dijo que hay forma de justificar esto :D

plot(ortogonales, comparisons=T) # Tira el mismo plot que para Bonferroni. Raro.

# FORMA DE JOSÉ:
emm <- emmeans(m9,specs=~TRATAMIENTO*tiempo_testeo)
confint(contrast(emm, method = list("3hs_alto_pos"=c(1,0,0,-1,0,0,0,0,0,0,0,0), 
                     "3hs_bajo_neg"=c(0,1,-1,0,0,0,0,0,0,0,0,0), 
                     "24hs_alto_pos"=c(0,0,0,0,1,0,0,-1,0,0,0,0), 
                     "24hs_bajo_neg"=c(0,0,0,0,0,1,-1,0,0,0,0,0), 
                     "48hs_alto_pos"=c(0,0,0,0,0,0,0,0,1,0,0,-1), 
                     "48hs_bajo_neg"=c(0,0,0,0,0,0,0,0,0,1,-1,0))))


##### TERCERA PROPUESTA: EFECTOS SIMPLES (COMPARACIÓN DE TODOS LOS TRATAMIENTOS PARA CADA TIEMPO)

ef_simples<-emmeans(m9,pairwise~TRATAMIENTO|tiempo_testeo,type="response")

ef_simples # A las 3hs no da nada significativo. A las 24hs tampoco. A las 48hs dan significativas las comparaciones constante alto vs contraste negativo y contraste negativo vs contraste positivo. No nos interesan mucho esas comparaciones.

plot(ef_simples, comparisons=T) 


##### CUARTA PROPUESTA: TUKEY (TODOS CONTRA TODOS, NO NOS INTERESA EN REALIDAD PERO PARA PROBAR. SI DA ALGO SIGNIFICATIVO ACÁ ES PORQUE ESTAMOS HACIENDO MAL LOS OTROS CONTRASTES)

tukey<-emmeans(m9,pairwise~TRATAMIENTO*tiempo_testeo,type="response")

tukey # Dan significativas solo comparaciones entre tiempos y contraste negativo vs contraste positivo a las 48hs.

plot(tukey, comparisons=T) 

#*******************************************************************************
############################ SIN 3HS ###########################################
#*******************************************************************************

# Dado que 3hs no presenta diferencias, vamos a probar hacer el modelo sin los datos de las 3hs para ver si aumentamos la potencia y obtenemos nuevas comparaciones significativas. Esto es porque creíamos que a las 3hs había "ruido". Sin embargo, luego de una charla con el director de Mili llegamos a la conclusión de que la info a las 3hs sí nos interesa porque es para ver si hay memoria a corto término. Que dé NS es información.

# Eliminamos las columnas de 3hs
wide_testeo_sin3 <- datos[,c(1,2,3,4,5,11,12)]

# Pasamos a formato long la base de datos
long_testeo_sin3 <- melt(wide_testeo_sin3,
                  id.vars = c("SEMANA", "ID", "ANT", "PROB", "TRATAMIENTO"),
                  variable.name = "tiempo_testeo",
                  value.name = "rta")

# Modelamos los datos sin 3hs con el mismo modelo
m9_sin3 <- glmmTMB(rta ~ TRATAMIENTO*tiempo_testeo + SEMANA + (1|ID), data=long_testeo_sin3, family="binomial")

# Estimación e inferencia
Anova(m9_sin3) # La interacción tratamiento*tiempo no da significativa así que podemos evaluar los tratamientos y el tiempo por separado. El efecto del tiempo no dio significativo. El efecto de los tratamientos sí sio significativo.

######################### COMPARACIONES

#### Efectos principales para tratamientos

ef_ppales_trat_sin3<-emmeans(m9_sin3,pairwise~TRATAMIENTO,type="response")

ef_ppales_trat_sin3 # Da solo significativa la comparación de contraste negativo vs contraste positivo.

plot(ef_ppales_trat_sin3, comparisons=T)


#### Contrastes ortogonales

ortogonales_sin3<-emmeans(m9_sin3,~TRATAMIENTO*tiempo_testeo,type="response",
                contr=list("24hs_alto_pos"=c(1,0,0,-1,0,0,0,0), 
                     "24hs_bajo_neg"=c(0,1,-1,0,0,0,0,0), 
                     "48hs_alto_pos"=c(0,0,0,0,1,0,0,-1), 
                     "48hs_bajo_neg"=c(0,0,0,0,0,1,-1,0)))

ortogonales_sin3 # Dan significativas las comparaciones constante alto vs contraste positivo a las 24 hs y constante bajo vs contraste negativo a las 48 hs. Igual que cuando hacíamos comparaciones ortogonales conservando los datos de las 3hs.


#### Tukey

tukey_sin3<-emmeans(m9_sin3,pairwise~TRATAMIENTO*tiempo_testeo,type="link")

tukey_sin3 # Dan significativas solo las comparaciones contraste positivo 24 hs vs contraste negativo 48 hs y contraste negativo vs contraste positivo ambos a 48 hs.

plot(tukey_sin3, comparisons=T)


#### Efectos simples

ef_simples_sin3<-emmeans(m9_sin3,pairwise~TRATAMIENTO|tiempo_testeo,type="link")

ef_simples_sin3 # A las 24 hs no dan significativas las comparaciones y las 48 hs dan significativas las comparaciones constante alto vs contraste negativo y contraste negativo vs contraste positivo. Ninguna nos interesa mucho.


#**************************** EN CONCLUSIÓN ************************************

# Sacar los datos de 3hs no ayudó. En los contrastes ortogonales dieron significativas las mismas comparaciones que cuando dejábamos las 3hs. Hasta sucede que cuando dejamos las 3hs, los p-valores de las comparaciones son menores, lo que nos lleva a pensar que en realidad sacando las 3hs perdemos potencia porque eliminamos muchas observaciones y la disminución de parámetros estimados no llega a compensarlas. Entonces, decidimos quedarnos con los datos de las 3hs que encima nos aportan información de que a las 3hs (memoria a corto término) no hay diferencias significativas entre los grupos.

# Pensamos en quedarnos con los contrastes ortogonales (con los datos que incluyen las 3hs) porque son los contrastes que queríamos hacer a priori y los resultados podrían tener una explicación biológica. Habría que confirmar que la línea de los contrastes ortogonales está bien hecha.

# Son los contrastes que queríamos hacer porque en otros experimentos que hizo Mili observó que las abejas aprenden más en el tiempo si son alimentadas con mayor concentración de azúcar, hasta llegar a un techo (también hay un piso). Entonces, tiene sentido comparar a los grupos que fueron alimentados con la misma concentración de azúcar en el entrenamiento.

# Pensamos que la comparación constante alto vs contraste positivo a las 48 hs no está dando significativa porque el control (constante alto a las 48 hs) tiene probabilidad muy cercana a 0,5, lo que hace que su varianza sea enorme y haya menor potencia en la comparación.


################################################################################
############################### GRÁFICO FINAL ##################################
################################################################################

res_modelo <- as.data.frame(ortogonales$emmeans)

ggplot(res_modelo,aes(x=tiempo_testeo,y=prob,colour=TRATAMIENTO,group=TRATAMIENTO)) +
  geom_line(linetype=2) +
  geom_point(size=2) +
  #geom_errorbar(aes(ymin=(prob-res_modelo$SE),ymax=(prob+res_modelo$SE)),
  #              width=.2,color="gray") +
  labs(x="Tiempo de testeo",y="Proporción de PER",title="Estimaciones del modelo") +
  ylim(0,1) + theme_bw() + 
  scale_color_hue(labels = c("Constante alto","Constante bajo",
                             "Contraste negativo","Contraste positivo")) +
  labs(col="Tratamiento") +
  geom_errorbar(aes(ymin=(prob-res_modelo$SE),ymax=(prob+res_modelo$SE)),
                width=.2,color="gray")


################################################################################
########################### VALIDACIÓN DEL MODELO ##############################
################################################################################

```

