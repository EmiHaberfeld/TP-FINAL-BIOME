---
title: "Trabajo Pr√°ctico Final  \nBiometr√≠a II - 2021"
author: "Mat√≠as Alem√°n, Milagros Azcueta, Manuel Fiz, Emilia Haberfeld, Diego Kafer, Juan Francisco Robuschi, Il√°n Shalom, Rodrigo Villarreal"
date: "16/11/2021"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, include=FALSE}
# Borrar objetos de la memoria
rm(list = ls()) 

################################################################################
####################### CARGA DE LIBRERIAS Y DATOS: ############################
################################################################################
#install.packages('tinytex')
tinytex::install_tinytex()
library(readxl)    # datos de excel
library(reshape2)  # melt
library(pastecs)   # tapply
library(ggplot2)   # gr√°ficos
library(ggeffects) # ggpredict (todav√≠a no lo usamos)
library(dplyr)
library(geepack)   # modelado con geeglm
library(MuMIn)     # model.sel
library(glmmTMB)   # modelado con glmmTMB
library(car)       # Anova
library(emmeans)   # comparaciones
library(DHARMa)

setwd("D:/Milagros Azcueta/Documents/GitHub/TP-FINAL-BIOME")
datos <- read_excel("datos.xlsx")
str(datos)
datos$SEMANA         <- as.factor(datos$SEMANA)
datos$ID             <- as.factor(datos$ID)
datos$ANT            <- as.factor(datos$ANT)
datos$PROB           <- as.factor(datos$PROB)
datos$TRATAMIENTO    <- as.factor(datos$TRATAMIENTO)
str(datos)
# Colmena no la vamos a incluir en el analisis porque esta explicada por Semana.
```
# Introducci√≥n
Los animales se encuentran constantemente tomando decisiones respecto a cu√°ndo alimentarse, aparearse, dormir, y dem√°s acciones (1). A trav√©s de aprendizajes y experiencias previas, son capaces de comparar dos o m√°s escenarios probables antes de realizar cualquier acci√≥n (2). La generaci√≥n de una expectativa respecto a dichos escenarios es un proceso que permite a los animales predecir la aparici√≥n de est√≠mulos (tanto aversivos como apetitivos) y de este modo, adaptar su comportamiento (3). Esta expectativa incide directamente en sus capacidades mn√©sicas, debido a que el aprendizaje depende de asociaciones entre claves externas y representaciones internas de dichas claves (4). Este proceso ha sido ampliamente estudiado en vertebrados, pero hay menos informaci√≥n disponible en invertebrados.

El objetivo de este trabajo es estudiar la modulaci√≥n de memorias a largo t√©rmino a partir de cambios en la expectativa de la recompensa. El modelo experimental es la abeja Apis mellifera y los experimentos fueron realizados en un contexto controlado dentro del laboratorio.

# Materiales y m√©todos
Abejas Apis mellifera fueron entrenadas bajo un condicionamiento cl√°sico del reflejo de extensi√≥n de prob√≥scide (de aqu√≠ en m√°s PER, por sus siglas en ingl√©s) (5,6): se administra un odorante a la vez que se tocan las antenas con una gota de sacarosa. La abeja extiende su prob√≥scide como reflejo de este est√≠mulo, y en ese momento se la alimenta con una soluci√≥n azucarada. De este entrenamiento, recibieron 4 ensayos. Terminada la etapa de entrenamiento, se realizaron tres testeos donde se present√≥ solo el odorante a 3, 24 y 48 hs posteriores al √∫ltimo ensayo de entrenamiento.

Las abejas se dividieron en 4 grupos experimentales dependiendo de la sacarosa recibida en las antenas y en la prob√≥scide. Los grupos "constante alto" y "constante bajo" recibieron tanto en las antenas como en la prob√≥scide az√∫car de concentraci√≥n 1,5 M y 0,5 M respectivamente. Por otro lado, los grupos "contraste positivo" y "contraste negativo" recibieron az√∫car de distinta concentraci√≥n en cada pieza sensorial: los animales del grupo contraste positivo recibieron sacarosa 0,5 M en las antenas y 1,5 M en su prob√≥scide. Por otro lado, los animales del contraste negativo recibieron az√∫car 1,5 M en las antenas para luego ser alimentados con sacarosa 0,5 M.

A continuaci√≥n se presentan gr√°ficos en base a una estad√≠stica descriptiva exploratoria para observar la tendencia de los datos:
```{r,include=FALSE}
################################################################################
############################### DESCRIPTIVA ####################################
################################################################################

################## ENTRENAMIENTO:
# PASAMOS DATOS ENTRENAMIENTO A LONG:
wide_entr <- datos[,c(1,2,3,4,5,6,7,8,9)]
long_entr <- melt(wide_entr,
                id.vars = c("SEMANA", "ID", "ANT", "PROB", "TRATAMIENTO"),
                variable.name = "tiempo_entr",
                value.name = "rta")

# PROBABILIDAD DE EXITO SEGUN TRATAMIENTO Y TIEMPO:
prob_exito_entr <- round(tapply(long_entr$rta,list(long_entr$TRATAMIENTO,long_entr$tiempo_entr),mean),2)
prob_exito_entr

# Creamos un data frame en formato long con estos valores:
prob_exito_entr_long <- as.data.frame.table(prob_exito_entr)
colnames(prob_exito_entr_long) <- c("TRATAMIENTO","nro_ensayo","proporcion_exitos")

# Reordenamos los levels para la leyenda del grafico:
prob_exito_entr_long$TRATAMIENTO <- factor(prob_exito_entr_long$TRATAMIENTO, levels = c("contraste_pos","constante_alto", "constante_bajo","contraste_neg"))

# Graficamente:
gp_entr <- ggplot(prob_exito_entr_long, aes(x=nro_ensayo, y=proporcion_exitos, colour=TRATAMIENTO, group=TRATAMIENTO)) +
  geom_line(linetype=2) +
  geom_point(size=2,shape=c(15,16,16,15,15,16,16,15,15,16,16,15,15,16,16,15)) + 
  #shape puntos
  labs(x="Numero de ensayo",y="Proporcion de PER",title="Curva de aprendizaje") +
  ylim(0,1) + theme_classic() +
  scale_colour_manual(labels = c("Contraste positivo","Constante alto",
                                 "Constante bajo","Contraste negativo"),
                      values=c("#00b050","#70ad47","#ed7c31","#ff0000")) +
  labs(col="Tratamiento") +
  guides(color = guide_legend(override.aes=list(shape=c(15,15,16,16)))) #leyenda

################## TESTEO:
# PASAMOS DATOS TEST A LONG:
wide_testeo <- datos[,c(1,2,3,4,5,10,11,12)]
long_testeo <- melt(wide_testeo,
                  id.vars = c("SEMANA", "ID", "ANT", "PROB", "TRATAMIENTO"),
                  variable.name = "tiempo_testeo",
                  value.name = "rta")

# PROBABILIDAD DE EXITO SEGUN TRATAMIENTO Y TIEMPO EN TESTEO:
prob_exito_testeo <- round(tapply(long_testeo$rta,list(long_testeo$TRATAMIENTO,long_testeo$tiempo_testeo), mean),2)
prob_exito_testeo

# Creamos un data frame en formato long con estos valores:
prob_exito_testeo_long <- as.data.frame.table(prob_exito_testeo)
colnames(prob_exito_testeo_long) <- c("TRATAMIENTO","tiempo_testeo","proporcion_exitos")

# Cambiamos los nombres del tiempo de testeo:
prob_exito_testeo_long$tiempo_testeo <- with(prob_exito_testeo_long, factor(tiempo_testeo,levels = c("3hs","24hs","48hs"),labels = c("3","24","48")))

# Reordenamos los levels para la leyenda del grafico:
prob_exito_testeo_long$TRATAMIENTO <- factor(prob_exito_testeo_long$TRATAMIENTO, levels = c("contraste_pos","constante_alto", "constante_bajo","contraste_neg"))

# Graficamente:
gp_testeo <- ggplot(prob_exito_testeo_long,aes(x=tiempo_testeo, y=proporcion_exitos, colour=TRATAMIENTO,group=TRATAMIENTO)) +
  geom_line(linetype=2) +
  geom_point(size=2,shape=c(15,16,16,15,15,16,16,15,15,16,16,15)) + #shape puntos
  labs(x="Tiempo de evaluacion (hs)",y="Proporcion de PER",
       title="Descriptiva evaluacion") +
  ylim(0,1) + theme_classic() +
  scale_colour_manual(labels = c("Contraste positivo","Constante alto",
                                 "Constante bajo","Contraste negativo"),
                      values=c("#00b050","#70ad47","#ed7c31","#ff0000")) +
  guides(color = guide_legend(override.aes=list(shape=c(15,15,16,16)))) + #leyenda
  labs(col="Tratamiento")

################## EXPLORAMOS SEMANA COMO COVARIABLE:

prob_exito_semana <- round(tapply(long_testeo$rta,list(long_testeo$SEMANA,long_testeo$tiempo_testeo), mean),2)
prob_exito_semana
# Creamos un data frame en formato long con estos valores:
prob_exito_semana_long <- as.data.frame.table(prob_exito_semana)
colnames(prob_exito_semana_long) <- c("SEMANA","tiempo_testeo","proporcion_exitos")
# Cambiamos los nombres del tiempo de testeo:
prob_exito_semana_long$tiempo_testeo <- with(prob_exito_semana_long, factor(tiempo_testeo,levels = c("3hs","24hs","48hs"),labels = c("3","24","48")))

# Graficamente:
gp_semana <- ggplot(prob_exito_semana_long, aes(x=tiempo_testeo, y=proporcion_exitos, colour=SEMANA,group=SEMANA)) +
  geom_line(linetype=2) +
  geom_point(size=2) +
  labs(x="Tiempo de evaluacion (hs)",y="Proporcion de PER",title="Proporcion de PER en cada semana",col="Semana") +
  ylim(0,1) + theme_classic()
```
```{r}
gp_entr   # Grafico de perfiles de la etapa de entrenamiento
```
**Figura 1:** Proporciones de PER para cada tratamiento en cada ensayo de entrenamiento. En la etapa de entrenamiento, se observa que todos los animales parten de una respuesta nula al odorante en el ensayo 1. En los ensayos subsiguientes todos los grupos parecen alcanzar una proporci√≥n de PER asint√≥tica alrededor de 0,6, lo que se traduce en un buen aprendizaje de la asociaci√≥n odorante-recompensa.
```{r}
gp_testeo # Grafico de perfiles de la etapa de evaluacion
```
**Figura 2:** Proporciones de PER para cada tratamiento en cada tiempo de evaluaci√≥n. Respecto a la etapa de evaluaci√≥n, a 3 hs los resultados parecen ser opuestos a la hip√≥tesis (los grupos CONSTANTE BAJO y CONTRASTE NEGATIVO tienen respuestas m√°s altas que CONSTANTE ALTO y CONTRASTE POSITIVO), pero luego, esta relaci√≥n se revierte en las pruebas a 24 y 48 hs.
```{r}
gp_semana # Grafico de perfiles de la etapa de evaluacion por semana
```
**Figura 3:** Respecto a la proporci√≥n de PER en cada tiempo de evaluaci√≥n en cada semana, se observa cierto grado de variabilidad en las respuestas. Resulta conveniente incluirla como variable explicatoria del modelo.

# Modelado
Como VR se midi√≥ la extensi√≥n de la prob√≥scide frente al olor (si-no). Al ser una variable dicot√≥mica, la distribuci√≥n de probabilidades esperada es una Bernoulli. El dise√±o es de medidas repetidas ya que cada abeja fue medida 7 veces (4 ensayos de entrenamiento + 3 testeos). Se realiz√≥ estad√≠stica descriptiva de la etapa de entrenamiento y un modelo estad√≠stico para la etapa de evaluaci√≥n ya que el mayor inter√©s del an√°lisis est√° depositado en las diferencias observables durante esta etapa. Como variables explicativas se incluyeron:

VE1: Tiempo de testeo ‚Üí cualitativa fija de 3 niveles (3, 24, 48 hs).

VE2: Tratamiento ‚Üí cualitativa fija de 4 niveles (constante alto, constante bajo, contraste positivo, contraste negativo)

VE3: ID de abeja ‚Üí cualitativa aleatoria de 132 niveles (abeja 1 a 132).

VE4: Semana de trabajo ‚Üí cualitativa aleatoria de 7 niveles (semanas 1 a 7). Covariable.

Se implement√≥ un modelo lineal generalizado condicional con la funci√≥n glmmTMB de la librer√≠a glmmTMB. Se opt√≥ por un modelo condicional ya que se compararon modelos marginales con distintas matrices de correlaci√≥n y, a partir de un ranking de QIC (el cual compara modelos seg√∫n su verosimilitud y cantidad de par√°metros estimados), el m√°s conveniente result√≥ ser un modelo marginal con matriz de simetr√≠a compuesta. Como los modelos condicionales tienen impl√≠cita una matriz de simetr√≠a compuesta y resultan m√°s familiares para su implementaci√≥n en R, se elige esta opci√≥n. 
Desde un punto de vista m√°s te√≥rico quisimos, en un principio, incluir a la variable ‚Äúsemana‚Äù como una de efectos aleatorios, dado que no presentamos preguntas o hip√≥tesis puntuales acerca de las diferencias entre semanas. Sin embargo, al chequear los supuestos, el supuesto de normalidad de los residuos de la variable de efectos aleatorios ‚ÄúID‚Äù no cumpl√≠a las expectativas.

Como soluci√≥n a este problema decidimos probar incluir en el modelo la variable semana como una de efectos fijos. El modelo ahora incluye m√°s par√°metros y por lo tanto logra un mejor ajuste, resultando en predichos m√°s precisos con nuestros datos. Es por esto que al chequear nuevamente los supuestos, se logra obtener una prueba satisfactoria de Shapiro-Wilk para los residuos de la variable de efectos aleatorios ‚ÄúID‚Äù.

## Modelo te√≥rico

##### *Escala del predictor lineal*

$logit$($\pi_{ijk}$) = $\mu$ + $\alpha_i$ + $\beta_j$ + $\alpha*\beta_{ij}$ + $\gamma_k$ + $A_{l(ij)(k)}$

##### *Escala de odds*

$\pi_{ijk}$/$(1-\pi_{ijk})$ = $e^{(\mu + \alpha_i + \beta_j + \alpha*\beta_{ij} + \gamma_k + A_{l(ij)(k)})}$

##### *Escala de probabilidades*

$\pi_{ijk}$ = $\frac{e^{(\mu + \alpha_i + \beta_j + \alpha*\beta_{ij} + \gamma_k + A_{l(ij)(k)})}}{1+e^{(\mu + \alpha_i + \beta_j + \alpha*\beta_{ij} + \gamma_k + A_{l(ij)(k)})}}$

Con *i* = 1 *a* 4, *j* = 1 *a* 3, *k* = 1 *a* ? y *l* = 1 *a* ?

*Siendo odds igual a la probabilidad de extensiÛn de probÛscide sobre la probabilidad de no extensiÛn.*

$Y_{ijk}\sim Bernoulli (\pi_{ijk})$

*Con Y siendo extensiÛn de la probÛscide frente al odorante.*

$A_l\sim NID(0, \sigma_{abejas}^2)$

```{r,include=FALSE}
################################################################################
############################### MODELADO #######################################
################################################################################

################## PRIMERA PROPUESTA: MODELO MARGINAL (GEEGLM)
# Para geeglm, las filas del data frame tienen que estar ordenadas por paciente y por tiempo:
long_testeo <- arrange(long_testeo,ID)

# Notacion de matrices de covarianza en geeglm:
# Estructura simple: independence
# Simetria compuesta: exchangeable
# AR1: ar1
# Desestructurada: unstructured

### Interaccion tratamiento*tiempo
m5 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="independence")
anova(m5)
m6 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="exchangeable")
anova(m6)
m7 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="ar1")
anova(m7)
m8 <- geeglm(formula=rta~TRATAMIENTO*tiempo_testeo+SEMANA,family=binomial,data=long_testeo,id=ID,
             corstr="unstructured")
anova(m8)

## SELECCION DE MODELOS (en geeglm rankeamos por QIC):
model.sel(m5,m6,m7,m8, rank = QIC)

# Estructura simple: la sacamos porque no estariamos declarando dependencia de datos entre tiempos para una misma abeja.
# Simetria compuesta: decimos que para cada abeja hay una misma correlacion entre tiempos.
# AR1: la sacamos porque a pesar de tener la misma cantidad de par√°metros que la de simetria compuesta, tiene un peor ajuste porque nuestros tiempos no son equidistantes como asume AR1, entonces el QIC es mayor.
# Desestructurada: la sacamos porque estima mas parametros, por eso el QIC da un poco mas alto.

################## SEGUNDA PROPUESTA: MODELO CONDICIONAL (GLMMTMB)

# Como elegimos simetria compuesta, probamos un modelo condicional:

# Semana como aleatoria:
m9 <- glmmTMB(rta ~ TRATAMIENTO*tiempo_testeo +  (1|SEMANA) + (1|ID), data=long_testeo, family="binomial")

# Semana como fija:
m10 <- glmmTMB(rta ~ TRATAMIENTO*tiempo_testeo + SEMANA + (1|ID), data=long_testeo, family="binomial")

################################################################################
########################### EVALUACI√ìN DE SUPUESTOS ############################
################################################################################

# Supuestos m9:
## Parte fija:
sim_m9 <- simulateResiduals(m9, n=1000)
plot(sim_m9)

# Supuestos para variable aleatoria Semana:
Bi_semana <- unlist(ranef(m9))
Bi_semana <- Bi_semana[1:7]
# QQPlot con estos residuos:
car::qqPlot(Bi_semana)
# Prueba de shapiro:
shapiro.test(Bi_semana)

# Supuestos para variable aleatoria ID:
Bi_ID <- unlist(ranef(m9))
Bi_ID <- Bi_ID[8:139]
# QQPlot con estos residuos:
# QQPlot con estos residuos:
car::qqPlot(Bi_ID)
# Prueba de shapiro:
shapiro.test(Bi_ID)

# Supuestos m10:
## Parte fija:
sim_m10 <- simulateResiduals(m9, n=1000)
plot(sim_m10)

# Supuestos para variable aleatoria ID:
Bi_ID_10 <- unlist(ranef(m10))
car::qqPlot(Bi_ID_10)
shapiro.test(Bi_ID_10)

# PARA M10 (SEMANA FIJA) NO HAY EVIDENCIAS PARA RECHAZAR CUMPLIMIENTO DE SUPUESTOS DE LA PARTE FIJA NI ALEATORIA (ID).
# PARA M9 NO SE CUMPLE LA NORMALIDAD DE LA VARIABLE ALEATORIA ID.

AIC(m9,m10)
# Elegimos usar m10 porque mejora el AIC y se cumplen los supuestos.

################################################################################
########################## ESTIMACI√ìN E INFERENCIA #############################
################################################################################
```
## Modelo implementado en R
```{r}
m10 <- glmmTMB(rta ~ TRATAMIENTO*tiempo_testeo + SEMANA + (1|ID), data=long_testeo, family="binomial")   # Modelo seleccionado: semana como VE de efectos fijos

Anova(m10)   # Prueba de ANOVA del modelo seleccionado
```
La interacci√≥n tratamiento*tiempo resulta significativa. Por ende, no es posible evaluar efectos principales. Las comparaciones se realizaron con contrastes ortogonales ya que se poseen hip√≥tesis a priori sobre las mismas.

## Contrastes a priori
Se espera que el grupo CONTRASTE POSITIVO aprenda la asociaci√≥n olor-az√∫car m√°s fuertemente que el CONSTANTE ALTO, debido a un mayor estado motivacional gracias a la "sorpresa" recibida en la prob√≥scide (az√∫car 1,5 M) en contraste con el az√∫car esperada que toc√≥ las antenas segundos antes (0,5 M). Caso opuesto, se espera que la proporci√≥n de animales del grupo CONTRASTE NEGATIVO que aprendan la asociaci√≥n sea menor que la proporci√≥n de animales del grupo CONSTANTE BAJO, debido a un estado motivacional degradado por la "decepci√≥n" de recibir az√∫car 0,5 M cuando esperaban 1,5 M.

Las comparaciones se realizaron entre grupos con igual concentraci√≥n de az√∫car en prob√≥scide, dado que la ingesta de alimento, la recompensa, es la se√±al post-ingestiva que permite la consolidaci√≥n de la memoria asociatva de largo t√©rmino.
```{r,include=FALSE}
################################################################################
############################### COMPARACIONES ##################################
################################################################################

# Seteamos el emmeans:
options(emmeans= list(emmeans = list(infer = c(TRUE, TRUE)),
                      contrast = list(infer = c(TRUE, TRUE))))


##### CONTRASTES ORTOGONALES (TENEMOS COMPARACIONES A PRIORI)

ortogonales<-emmeans(m10,~TRATAMIENTO*tiempo_testeo,type="response",
                contr=list("3hs_alto_pos"=c(1,0,0,-1,0,0,0,0,0,0,0,0), 
                     "3hs_bajo_neg"=c(0,1,-1,0,0,0,0,0,0,0,0,0), 
                     "24hs_alto_pos"=c(0,0,0,0,1,0,0,-1,0,0,0,0), 
                     "24hs_bajo_neg"=c(0,0,0,0,0,1,-1,0,0,0,0,0), 
                     "48hs_alto_pos"=c(0,0,0,0,0,0,0,0,1,0,0,-1), 
                     "48hs_bajo_neg"=c(0,0,0,0,0,0,0,0,0,1,-1,0)))
```
# Resultados
```{r}
ortogonales # Implementaci√≥n de contrastes ortogonales
```
```{r,include=FALSE}
################################################################################
############################### GR√ÅFICO FINAL ##################################
################################################################################

res_modelo <- as.data.frame(ortogonales$emmeans)

# Cambiamos los nombres del tiempo de testeo:
res_modelo$tiempo_testeo <- with(res_modelo, factor(tiempo_testeo,
                                                    levels = c("3hs","24hs","48hs"),
                                                    labels = c("3","24","48")))
# Reordenamos los levels para la leyenda del grafico:
res_modelo$TRATAMIENTO <- factor(res_modelo$TRATAMIENTO,
                                 levels = c("contraste_pos","constante_alto",
                                            "constante_bajo","contraste_neg"))

# Graficamos:
gp_final <- ggplot(res_modelo,aes(x=tiempo_testeo,y=prob,group=TRATAMIENTO,color=TRATAMIENTO)) +  
  labs(x="Tiempo de evaluacion (hs)",y="Proporcion de PER",title="Estimaciones del modelo") +
  geom_errorbar(aes(ymin=(prob-res_modelo$SE),ymax=(prob+res_modelo$SE)),
                width=.2,color="lightgrey") +
  geom_line(linetype=2) +
  geom_point(size=2,shape=c(15,16,16,15,15,16,16,15,15,16,16,15)) + #shape puntos
  labs(col="Tratamiento") +
  theme_classic() +
  ylim(0,1) +
  scale_colour_manual(labels = c("Contraste positivo","Constante alto",
                                 "Constante bajo","Contraste negativo"),
                      values=c("#00b050","#70ad47","#ed7c31","#ff0000")) + #leyenda
  guides(color = guide_legend(override.aes=list(shape=c(15,15,16,16)))) +  #leyenda
  annotate(geom="text",x="24",y=1,label="*",color="#00b050",size=10) + #significancia
  annotate(geom="text",x="48",y=1,label="*",color="#ff0000",size=10)   #significancia
```
```{r}
gp_final  # Gr√°fico final, medidas resumen del modelo
```
**Figura 4:** Proporciones estimadas de PER para cada tratamiento en cada tiempo de evaluaci√≥n. Los resultados se informan como la media +/- el error est√°ndar de cada combinaci√≥n de tiempo y tratamiento. A partir de un modelo mixto/condicional, se vio que la proporci√≥n de PER a 24 hs es mayor para el grupo CONTRASTE POSITIVO que para el grupo CONSTANTE ALTO (p<0.05) y que la proporci√≥n de PER a 48 hs es menor para el grupo CONTRASTE NEGATIVO que para el grupo CONSTANTE BAJO (p<0.05).

En el primer tiempo de evaluaci√≥n (3 hs) no se observaron diferencias significativas en los contrastes (p>0,05). 

A 24 hs se observaron diferencias significativas entre los grupos CONSTANTE ALTO y CONTRASTE POSITIVO. Se estima que la chance de extensi√≥n de prob√≥scide para el grupo CONTRASTE POSITIVO aumenta en promedio entre un 2,96% y un 84,2% respecto al grupo CONSTANTE ALTO, con un 95% de confianza (p<0,05). No se observaron diferencias significativas en la comparaci√≥n CONSTANTE BAJO vs CONTRASTE NEGATIVO a 24 hs (p>0,05). 

En la evaluaci√≥n a 48 hs, se observaron diferencias significativas entre los grupos CONSTANTE BAJO y CONTRASTE NEGATIVO. Se estima que la chance de extensi√≥n de prob√≥scide para el grupo CONTRASTE NEGATIVO disminuye en promedio entre un 21,4% y un 97,93% respecto al grupo CONSTANTE BAJO, con un 95% de confianza (p<0,05). No se observaron diferencias significativas en la comparaci√≥n CONSTANTE ALTO vs CONTRASTE POSITIVO a 48 hs (p>0,05), aunque la tendencia de las estimaciones coincide con lo observado a 24 hs.

# Discusi√≥n
Debido a que la interacci√≥n tratamiento*tiempo result√≥ significativa, se realizaron contrastes ortogonales teniendo en cuenta ambas variables. Si nos situamos en primer lugar en las comparaciones en t = 3 hs, se observa que ninguno de los dos contrastes propuestos mostr√≥ diferencias significativas. Lo que es m√°s curioso aun es que la tendencia de la respuesta parece ser opuesta a la esperada por los contrastes a priori: los grupos CONTRASTE NEGATIVO y CONSTANTE BAJO son aquellos que mayor proporci√≥n de PER presentaron. Debido a que la memoria observada a las 3 hs posteriores de finalizado el √∫ltimo ensayo de entrenamiento es una memoria de corto t√©rmino, puede estar influida por diversos fen√≥menos ajenos al tratamiento aplicado. En particular, se propone que en este punto temporal hay un conflicto en relaci√≥n a la expresi√≥n de la memoria generada. Los animales de los grupos CONTRASTE NEGATIVO y CONSTANTE BAJO son los que menos az√∫car ingirieron (en t√©rminos nutricionales), ya que siempre consumieron az√∫car de concentraci√≥n 0,5 M. Por lo tanto, es muy probable que a 3 hs estos animales est√©n m√°s motivados que los otros dos grupos y que por ende, lo que parece ser una mayor retenci√≥n de la memoria (que solo es posible de observar a trav√©s de la extensi√≥n de la prob√≥scide en este experimento) sea un reflejo de la motivaci√≥n de estos animales por seguir ingiriendo az√∫car. En contraste, las abejas de los grupos CONTRASTE POSITIVO y CONSTANTE ALTO habr√≠an alcanzado un nivel de saciedad m√°s alto, respondiendo menos al est√≠mulo que se asocia con la llegada de az√∫car (odorante). 

El d√≠a siguiente al aprendizaje, se busc√≥ estudiar la consolidaci√≥n de memoria de largo t√©rmino en las abejas. Al hacer las comparaciones a t = 24 hs se observaron diferencias significativas entre los grupos CONSTANTE ALTO y CONTRASTE POSITIVO. Esto sugiere que un mismatch positivo entre lo que el animal capta con las antenas y lo que ingiere genera una consolidaci√≥n de memoria de largo t√©rmino m√°s robusta, la cual tiene un efecto directo en el comportamiento. Creemos que el animal al sensar con las antenas genera expectativas de lo que va a ingerir y es la sorpresa positiva que siente lo que generar√≠a un estado motivacional que predispone a una mayor retenci√≥n de la experiencia. Por otro lado, al comparar los grupos CONSTANTE BAJO contra CONTRASTE NEGATIVO, no observamos diferencias significativas. Sin embargo se pudo observar una tendencia que encaja con lo teorizado a priori: aquellos animales pertenecientes al grupo contraste negativo presentaron una menor proporci√≥n de PER que el grupo constante bajo. Esto sugiere que puede haber un efecto en la consolidaci√≥n de la memoria de largo t√©rmino por mismatch negativo. Si trasladamos la evaluaci√≥n a 24 hs al entorno natural de un animal "decepcionado", se relaciona con la evocaci√≥n de una memoria de un sitio que otorga recompensas pero que no alcanzan la calidad esperada por la abeja. Es probable que la relaci√≥n de compromiso entre un est√≠mulo positivo (presencia de una recompensa) y un est√≠mulo menos motivante (que la recompensa no sea de la calidad esperada) genere que los animales igualmente visiten la fuente de alimento (en este caso, ser√≠a an√°logo a responder al odorante). Sin embargo, pasadas 48 hs del encuentro con ese sitio, es altamente probable que ese mismo animal haya encontrado una locaci√≥n que le permita obtener recursos de mayor calidad. Por lo tanto, se propone que en el grupo CONTRASTE NEGATIVO se genera una traza mn√©sica inhibitoria en relaci√≥n a la degradaci√≥n de la recompensa esperada, que resulta evidente en evaluaciones posteriores a las 24 hs. 

En la evaluaci√≥n a 48 hs no se observaron diferencias significativas entre los grupos CONSTANTE ALTO y CONTRASTE POSITIVO. Esto puede explicarse en base a la distribuci√≥n de probabilidades de nuestros datos. En una distribuci√≥n Bernoulli, el punto de m√°xima varianza se encuentra en p=0,5. Trasladado al ejemplo de este trabajo, ser√≠a el caso en el cual el 50% de las abejas extiende su prob√≥scide y el 50% no lo hace, bajo un mismo tratamiento. Debido a que la proporci√≥n de PER estimada para el grupo CONSTANTE ALTO a 48 hs es de 0,51, este grupo tiene la m√°xima varianza posible. Por lo tanto, a pesar de que se mantiene la misma tendencia observada en la evaluaci√≥n a las 24 hs, la comparaci√≥n con el grupo CONTRASTE POSITIVO resulta no significativa en este caso. Por otro lado, la comparaci√≥n entre los grupos CONSTANTE BAJO y CONTRASTE NEGATIVO result√≥ significativa. Se pudo observar que la sorpresa negativa que sufre el animal en este √∫ltimo grupo es capaz de modular la memoria a largo t√©rmino. Si bien la memoria del grupo CONSTANTE BAJO decae en el tiempo, la memoria del grupo CONTRASTE NEGATIVO lo hace a un ritmo mayor.

Como conclusi√≥n, resulta interesante haber observado que no solo es importante que haya un mismatch entre lo esperado y lo obtenido para modular una memoria a largo t√©rmino, sino que tambi√©n la valencia de ese contraste tendr√° un efecto diferencial sobre esa memoria.

# Bibliograf√≠a
1. McFarland, D. J. Decision making in animals. Nature 269, 15‚Äì21 (1977).
2. Menzel, R. & Giurfa, M. Dimensions of Cognition in an Insect, the Honeybee. Behav. Cogn. Neurosci. Rev. 5, 24‚Äì40 (2006).
3. Gil, M., De Marco, R. J. & Menzel, R. Learning reward expectations in honeybees. Learn. Mem. 14, 491‚Äì6 (2007).
4. Rescorla, R. A. A Pavlovian analysis of goal-directed behavior. Am. Psychol. 42, 119‚Äì129 (1987).
5. Bitterman, M. E., Menzel, R., Fietz, A. & Sch√§fer, S. Classical conditioning of proboscis extension in honeybees (Apis mellifera). J. Comp. Psychol. 97, 107‚Äì119 (1983).
6. Takeda, K. Classical conditioned response in the honey bee. J. Insect Physiol. 6, 168‚Äì179 (1961).